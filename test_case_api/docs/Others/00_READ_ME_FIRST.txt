â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                            â•‘
â•‘              ğŸ‰ TEST CASE GENERATOR API - READY TO USE! ğŸ‰                â•‘
â•‘                                                                            â•‘
â•‘                         Flask + Ollama LLM                                â•‘
â•‘                  System-Level Integration Black-Box Testing               â•‘
â•‘                                                                            â•‘
â•‘                       (Direct Python Execution)                           â•‘
â•‘                                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


ğŸ“ PROJECT LOCATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

/Users/emersonsolahd/EMR_SOLAHD/00_DCUPS/sdu_ups/01_plan/test_case_api/


âš¡ QUICK START (5 MINUTES)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Step 1: Install
  $ cd /Users/emersonsolahd/EMR_SOLAHD/00_DCUPS/sdu_ups/01_plan/test_case_api
  $ python3 -m venv venv
  $ source venv/bin/activate
  $ pip install -r requirements.txt

Step 2: Run
  $ python app.py

Step 3: Test (in another terminal)
  $ curl http://localhost:5000/health

Step 4: Generate
  $ curl -X POST http://localhost:5000/generate \
    -H "Content-Type: application/json" \
    -d @samples/single_requirement.json | jq '.Test_Case'

âœ… DONE!


ğŸ“š DOCUMENTATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ‘‰ START HERE:
   â€¢ START_HERE.md        - Complete setup summary (READ THIS FIRST!)
   â€¢ QUICKSTART.md        - 5-minute setup guide
   â€¢ WELCOME.md           - Overview & features

FULL DOCS:
   â€¢ README.md            - Complete documentation
   â€¢ API_SPECIFICATION.md - All endpoints
   â€¢ PROJECT_OVERVIEW.md  - Architecture

ADVANCED:
   â€¢ CUSTOMIZATION_GUIDE.md - Customize test generation
   â€¢ INDEX.md             - File navigation guide


ğŸ“¦ WHAT'S INCLUDED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ app.py                     - Flask REST API server
âœ“ client.py                  - Python client library
âœ“ requirements.txt           - Dependencies (4 packages)
âœ“ .env.example              - Configuration template
âœ“ test_api.sh               - Test script
âœ“ instructions/             - Customizable system prompt
âœ“ samples/                  - Example requirements
âœ“ 10 documentation files    - Complete guides


ğŸ¯ WHAT IT DOES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

INPUT:  Software requirements in JSON format
        {
          "REQUIREMENTS_ID": "REQ-001-01",
          "DESCRIPTION": "System shall...",
          "CATEGORY": "Functional"
        }

PROCESS: Uses Ollama LLM to understand requirement
         Generates detailed test case using system instructions
         Focuses on system-level, black-box testing approach

OUTPUT: JSON with populated Test_Case field
        {
          "REQUIREMENTS_ID": "REQ-001-01",
          "DESCRIPTION": "...",
          "Test_Case": "OBJECTIVE: ...\nPRECONDITIONS: ...\n..."
        }


ğŸš€ KEY FEATURES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Single test case generation    - Via REST API or Python client
âœ… Batch processing               - Multiple requirements at once
âœ… File upload                    - Process bulk JSON files
âœ… Customizable instructions      - Control test generation style
âœ… Multiple Ollama models         - Speed vs quality tradeoff
âœ… Python client library          - Easy programmatic access
âœ… System-level focus             - Black-box testing emphasis
âœ… Hardware/embedded support      - Power systems, firmware, etc.
âœ… No authentication              - Perfect for internal use
âœ… Production-ready               - Error handling, validation


ğŸ¯ API ENDPOINTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

GET  /health                       - Check API & Ollama status
GET  /models                       - List available models
GET  /instructions                 - Get system instructions
POST /instructions                 - Update system instructions
POST /generate                     - Single test case
POST /generate/batch               - Multiple test cases
POST /generate/file                - Upload & process file


ğŸ’» USAGE EXAMPLES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Single:
  curl -X POST http://localhost:5000/generate \
    -H "Content-Type: application/json" \
    -d @samples/single_requirement.json

Batch:
  curl -X POST http://localhost:5000/generate/batch \
    -H "Content-Type: application/json" \
    -d @samples/batch_requirements.json

Upload:
  curl -X POST http://localhost:5000/generate/file \
    -F "file=@requirements.json"

Python:
  from client import TestCaseGeneratorClient
  client = TestCaseGeneratorClient()
  result = client.generate(requirement)


âš™ï¸ CONFIGURATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

File: .env (copy from .env.example)

Key settings:
  OLLAMA_BASE_URL=http://localhost:11434
  OLLAMA_MODEL=llama2
  PORT=5000

Most defaults work for local Ollama - no changes needed!


ğŸ†˜ TROUBLESHOOTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Problem: "Connection refused"
Fix:     Verify Ollama: curl http://localhost:11434/api/tags

Problem: "Model not found"
Fix:     Pull model: ollama pull llama2

Problem: "Timeout"
Fix:     Increase OLLAMA_TIMEOUT in .env or use mistral model

Problem: "Poor test quality"
Fix:     Edit instructions/system_instructions.md

See QUICKSTART.md for more troubleshooting.


ğŸ“ LEARNING PATHS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸŸ¢ FAST (15 min):
   1. Read QUICKSTART.md
   2. Run 4 commands
   3. Test with curl

ğŸŸ¡ FULL (2 hours):
   1. Read WELCOME.md
   2. Install and test
   3. Read README.md
   4. Try Python client

ğŸ”´ ADVANCED (2-3 hours):
   1. Read PROJECT_OVERVIEW.md
   2. Read CUSTOMIZATION_GUIDE.md
   3. Customize instructions
   4. Integrate into workflow


âœ¨ WHAT CHANGED (REVISED)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

REMOVED:
  âœ— Dockerfile          (No Docker needed)
  âœ— docker-compose.yml  (Running directly with Python)

WHY:
  Direct Python execution is simpler and better for your use case.
  Easier to debug, customize, and integrate.


ğŸŒŸ NEXT STEPS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ğŸ‘‰ Read START_HERE.md (complete overview)
   OR read QUICKSTART.md (fast track)

2. Install dependencies (4 commands, 1 minute)

3. Run: python app.py

4. Test: curl http://localhost:5000/health

5. Generate: curl -X POST ... (see examples above)


ğŸ‰ YOU'RE READY!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Everything is set up and ready to go:

âœ“ Complete API (app.py)
âœ“ Python client (client.py)
âœ“ All dependencies (requirements.txt)
âœ“ Comprehensive docs (10 files)
âœ“ Examples (samples/)
âœ“ Customizable (instructions/)

ğŸ‘‰ Start with START_HERE.md or QUICKSTART.md

Questions? Check the documentation or see INDEX.md

Good luck! ğŸš€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Version: 1.0 Revised (October 2024)
Status: Production Ready âœ…
Execution: Direct Python (No Docker)
